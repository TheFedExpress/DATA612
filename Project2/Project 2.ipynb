{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 Content-Based and Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Collaborative Filtering\n",
    "\n",
    "We'll use the Python \"surprise\" library.  This library offers several packages the support recommender systems, including nearest neighbor-based methods and matrix factoriaztion.  In this section, we'll take advantage of the nearest neighbor algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import gensim\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore, KNNBaseline, KNNBasic\n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "For our data, we'll use a \"The Movies Dataset\" from kaggle.  This dataset includes a table of 26 million ratings from hundreds of thousands of users.  We subset this data offline because finding a free method of storing this amount of data would be difficult.  Our subset includes all ratings from the top 10,000 users and top 2,000 movies.  The rating scale ranges between .5 and 5 in intervals of .5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18276.0</td>\n",
       "      <td>4545.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18276.0</td>\n",
       "      <td>4545.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18276.0</td>\n",
       "      <td>4205.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>8644.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "0  18276.0   4545.0     2.0\n",
       "1  18276.0   4545.0     2.0\n",
       "2  18276.0   4205.0     5.0\n",
       "3   9279.0   8644.0     2.5\n",
       "4   9279.0   8464.0     4.0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'https://raw.githubusercontent.com/TheFedExpress/DATA612/master/Project2/movies_medium.csv'\n",
    "movies = (pd.read_csv(path)\n",
    "          .drop(['Unnamed: 0', 'timestamp'], axis = 1)\n",
    "          .dropna()\n",
    "#          .groupby(['userId', 'movieId'])\n",
    "#          .mean()\n",
    "#          .reset_index()\n",
    ")\n",
    "\n",
    "reader = Reader(rating_scale=(.5, 5))\n",
    "\n",
    "rec_data = Dataset.load_from_df(movies, reader)\n",
    "trainset = rec_data.build_full_trainset()\n",
    "\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/72.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_user = movies.groupby('userId')['rating'].mean()\n",
    "layout = {'xaxis' : {'title': 'avg rating'}, 'title' : 'Distribution of Average User Ratings',\n",
    "         'yaxis': {'title' : 'Users'}\n",
    "}\n",
    "data = [go.Histogram(x = avg_user.values)]\n",
    "py.iplot(go.Figure(data = data, layout = layout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most users are somewhat generous with their ratings, with a mode of 4.  Some users are tougher than others, indicating that we might want to standardize ratings by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/74.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_movie = movies.groupby('movieId')['rating'].mean()\n",
    "layout = {'xaxis' : {'title': 'avg rating'}, 'title' : 'Distribution of Average Movie Ratings',\n",
    "         'yaxis': {'title' : 'Movies'}\n",
    "}\n",
    "data = [go.Histogram(x = avg_movie.values)]\n",
    "py.iplot(go.Figure(data = data, layout = layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie ratings are a little less right-skewed.  There is a fair amount of weight between 1 and 3, indicating there are some unpopular movies in our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models\n",
    "\n",
    "\n",
    "The Surprise library frames recomendations a bit more like a regression problem than the recommenderlab package.  This is the reason for its sklearn-like api.  The dataset is the input and predicted ratings are the featured output attribute.  **This framework can still be used for recommendations by choosing items with the highest predicted rating.**\n",
    "\n",
    "We'll try 4 model types, 3 of which use a similarity matrix and take the K most similar users/items, however the expected rating is computed with slightly different formulas.  The last model type will be the baseline model.\n",
    "\n",
    "- KNNBasic: Raw ratings are weighted by similarities.  Item-based uses the given user's rating of the similar items, while user-based computes the expected rating of an item based on the similar user's rating of that item\n",
    "- KNNWithZScore: Similar to basic, but starts with the mean of a user/item and adds Z-scores weighted by similarity\n",
    "- KNNBaseline: Starts with the base line rating and adds (baseline rating - actual rating) of similar items/users weighte by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'k' : [30,40,50], \n",
    "              'sim_options' : {'user_based': [False, True], \n",
    "              'name': ['cosine', 'pearson', 'pearson_baseline']}\n",
    "              \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mod(algo, data):\n",
    "\n",
    "    cv = GridSearchCV(algo, param_grid, cv = 3, n_jobs = -1)# set cv folds to 3 in the interst of time\n",
    "    cv.fit(data)\n",
    "\n",
    "    full_frame = pd.DataFrame.from_dict( cv.cv_results)\n",
    "    results_df = pd.concat([full_frame[['mean_test_rmse', 'mean_test_mae', 'param_k']], \n",
    "               json_normalize(cv.cv_results['param_sim_options'])], axis = 1)\n",
    "    return cv, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_mod(results_df, algo):\n",
    "\n",
    "    fig = tools.make_subplots(rows=1, cols=2, subplot_titles = ('Item Based', 'User Based'))\n",
    "    i = 1\n",
    "    for filter_type in  results_df.user_based.unique():\n",
    "        for item in results_df.name.unique():\n",
    "            df_temp = results_df.loc[(results_df.user_based == filter_type) & (results_df.name == item)]\n",
    "            trace = go.Scatter(\n",
    "                x = df_temp.param_k,\n",
    "                y = df_temp.mean_test_rmse,\n",
    "                mode = 'lines+markers',\n",
    "                name = item,\n",
    "            )\n",
    "            fig.append_trace(trace,1,i)\n",
    "            fig['layout']['yaxis1'].update(title = 'RMSE')\n",
    "            fig['layout']['xaxis' + str(i)].update(title = 'K')\n",
    "        i+=1\n",
    "    fig['layout'].update(title=algo)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.749864</td>\n",
       "      <td>0.570235</td>\n",
       "      <td>0.118682</td>\n",
       "      <td>0.070841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756086</td>\n",
       "      <td>0.575985</td>\n",
       "      <td>0.098736</td>\n",
       "      <td>0.065821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.758694</td>\n",
       "      <td>0.574949</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>0.067817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.753087</td>\n",
       "      <td>0.571256</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>0.497668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.754748</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>0.204451</td>\n",
       "      <td>0.116688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_rmse  test_mae  fit_time  test_time\n",
       "0   0.749864  0.570235  0.118682   0.070841\n",
       "1   0.756086  0.575985  0.098736   0.065821\n",
       "2   0.758694  0.574949  0.104720   0.067817\n",
       "3   0.753087  0.571256  0.127659   0.497668\n",
       "4   0.754748  0.570635  0.204451   0.116688"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "algo = BaselineOnly()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cv1 = cross_validate(algo, rec_data, measures=['RMSE', 'MAE'], cv=5)\n",
    "pd.DataFrame.from_dict( cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/76.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cv, basic_results = cv_mod(KNNBasic, rec_data)\n",
    "basic_fig = graph_mod(basic_results, 'KNN Basic')\n",
    "py.iplot(basic_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/78.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore_cv, zscore_results = cv_mod(KNNWithZScore, rec_data)\n",
    "z_fig = graph_mod(zscore_results, 'KNN With Z-Score')\n",
    "py.iplot(z_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/80.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv, baseline_results = cv_mod(KNNBaseline, rec_data)\n",
    "base_fig = graph_mod(baseline_results, 'KNN KNNBaseline')\n",
    "py.iplot(base_fig, layout = layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/TheFedExpress/DATA612/master/Project2/movies_metadata.csv'\n",
    "def make_int(df, column):\n",
    "    df = df.copy()\n",
    "    df[column] =  df[column].map(lambda x: x.replace('-', ''))\n",
    "    return df\n",
    "\n",
    "movies_metadata = (pd.read_csv(path)\n",
    "                       .loc[:, ['id', 'budget', 'overview', 'runtime']]\n",
    "                       .pipe(make_int, 'id')\n",
    "                       .drop_duplicates('id')\n",
    ")\n",
    "\n",
    "movies_metadata['id'] = movies_metadata['id'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import re\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "import numpy as np\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(desc):\n",
    "    words = []\n",
    "    try:\n",
    "        for item in simple_preprocess(desc, min_len = 3):\n",
    "             if item not in STOPWORDS or item in ['he', 'she', 'her', 'his']:\n",
    "                words.append(lemmatize_stemming(item))\n",
    "        return words\n",
    "    except(TypeError):\n",
    "        return np.nan\n",
    "\n",
    "movies_metadata['movie_words'] = movies_metadata['overview'].map(preprocess)\n",
    "movie_words = movies_metadata[['id', 'movie_words']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(movie_words['movie_words'])\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=20000)\n",
    "dictionary.compactify()\n",
    "corpus = [dictionary.doc2bow(item) for item in movie_words['movie_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus = corpus, num_topics = 50, id2word = dictionary, passes = 10, alpha = .0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29,\n",
       "  '0.029*\"greatest\" + 0.022*\"youth\" + 0.017*\"controversi\" + 0.016*\"roll\" + 0.015*\"decad\" + 0.015*\"biggest\" + 0.013*\"convers\" + 0.012*\"traffic\" + 0.011*\"roger\" + 0.011*\"cours\"'),\n",
       " (1,\n",
       "  '0.027*\"comedian\" + 0.025*\"moscow\" + 0.022*\"wall\" + 0.021*\"seem\" + 0.020*\"air\" + 0.019*\"transport\" + 0.019*\"cold\" + 0.018*\"sinist\" + 0.016*\"supernatur\" + 0.016*\"christian\"'),\n",
       " (23,\n",
       "  '0.025*\"bank\" + 0.023*\"insid\" + 0.020*\"hold\" + 0.020*\"trap\" + 0.018*\"bar\" + 0.018*\"fortun\" + 0.015*\"gold\" + 0.014*\"henri\" + 0.013*\"rob\" + 0.012*\"key\"'),\n",
       " (22,\n",
       "  '0.045*\"night\" + 0.034*\"compani\" + 0.027*\"head\" + 0.026*\"blood\" + 0.024*\"club\" + 0.017*\"eat\" + 0.017*\"food\" + 0.015*\"busi\" + 0.014*\"job\" + 0.014*\"shop\"'),\n",
       " (4,\n",
       "  '0.023*\"realiti\" + 0.022*\"achiev\" + 0.021*\"engin\" + 0.020*\"scienc\" + 0.019*\"generat\" + 0.019*\"technolog\" + 0.018*\"tortur\" + 0.017*\"influenc\" + 0.017*\"fiction\" + 0.016*\"resort\"'),\n",
       " (5,\n",
       "  '0.062*\"island\" + 0.037*\"japanes\" + 0.033*\"amp\" + 0.028*\"light\" + 0.025*\"captain\" + 0.022*\"sam\" + 0.017*\"landscap\" + 0.015*\"forget\" + 0.014*\"tribe\" + 0.013*\"sun\"'),\n",
       " (49,\n",
       "  '0.041*\"life\" + 0.020*\"live\" + 0.018*\"comedi\" + 0.016*\"time\" + 0.013*\"world\" + 0.012*\"stori\" + 0.012*\"dream\" + 0.011*\"work\" + 0.011*\"new\" + 0.011*\"person\"'),\n",
       " (35,\n",
       "  '0.114*\"town\" + 0.079*\"small\" + 0.048*\"villag\" + 0.031*\"local\" + 0.028*\"angel\" + 0.021*\"los\" + 0.015*\"set\" + 0.014*\"communiti\" + 0.012*\"creatur\" + 0.012*\"citizen\"'),\n",
       " (8,\n",
       "  '0.028*\"priest\" + 0.020*\"trial\" + 0.019*\"notori\" + 0.018*\"handsom\" + 0.017*\"languag\" + 0.017*\"spanish\" + 0.016*\"texa\" + 0.016*\"eddi\" + 0.015*\"smith\" + 0.015*\"judg\"'),\n",
       " (40,\n",
       "  '0.119*\"school\" + 0.093*\"high\" + 0.063*\"student\" + 0.025*\"class\" + 0.020*\"univers\" + 0.012*\"complex\" + 0.011*\"teenag\" + 0.010*\"graduat\" + 0.010*\"studi\" + 0.009*\"medic\"')]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = lda.print_topics(num_topics = 10)\n",
    "topics = [lda.get_document_topics(element) for element in corpus]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clus = []\n",
    "for i in range(len(topics)):\n",
    "    for j in range(len(topics[i])):\n",
    "        if topics[i][j][1] >= .1:\n",
    "            all_clus.append({\"id\": movie_words.iloc[i, 0], \"top_num\":topics[i][j][0], \"percentage\":topics[i][j][1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = (pd.DataFrame(all_clus)\n",
    "              .pivot(index = 'id', columns = 'top_num', values = 'percentage')\n",
    ")\n",
    "full_df = movies_metadata.merge(new_df, on = 'id').rename(columns = {'id': 'movieId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "4993.0    2302\n",
       "7153.0    2167\n",
       "2858.0    1901\n",
       "3481.0    1504\n",
       "3793.0    1404\n",
       "dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#movies.groupby('userId').size().sort_values(ascending = False).head(5)\n",
    "movies.groupby('movieId').size().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=-1, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.6),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'max_depth': [3, 5, 7, 9], 'n_estimators': [750, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "final_df = movies.merge(full_df, on = 'movieId')\n",
    "\n",
    "def impute_median(df, column):\n",
    "    df = df.copy()\n",
    "    df[column] = df.loc[df[column] == 0, column].median()\n",
    "    return df\n",
    "\n",
    "X = (final_df.pipe(impute_median, 'budget')\n",
    "         .pipe(impute_median, 'runtime')\n",
    "         .fillna(0)\n",
    "         .drop(columns = ['rating', 'userId', 'movieId', 'overview', 'movie_words'])\n",
    "         .loc[final_df['userId'] == 741]\n",
    ")\n",
    "y = final_df.loc[final_df['userId'] == 741, 'rating']\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'learning_rate': [.01, .05, .1],\n",
    "    'max_depth': [3,5,7,9],\n",
    "    'n_estimators': [750, 1000]\n",
    "    \n",
    "}\n",
    "gb = xgb.XGBRegressor(objective = 'reg:linear', subsample = .6, colsample_bytree = .6, nthread = -1)\n",
    "regressor = GridSearchCV(gb, xgb_param_grid, cv = 3, scoring = 'neg_mean_squared_error')\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.628168</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.640225</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.611460</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.614949</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.599182</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.601277</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.596463</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.598364</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.665432</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.665432</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.604249</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.604246</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.584202</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.584201</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.576201</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.576201</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.597825</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.597824</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.599179</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.599175</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.613601</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.613601</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.613664</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.613663</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  learning_rate  max_depth  n_estimators\n",
       "0         -0.628168           0.01          3           750\n",
       "1         -0.640225           0.01          3          1000\n",
       "2         -0.611460           0.01          5           750\n",
       "3         -0.614949           0.01          5          1000\n",
       "4         -0.599182           0.01          7           750\n",
       "5         -0.601277           0.01          7          1000\n",
       "6         -0.596463           0.01          9           750\n",
       "7         -0.598364           0.01          9          1000\n",
       "8         -0.665432           0.05          3           750\n",
       "9         -0.665432           0.05          3          1000\n",
       "10        -0.604249           0.05          5           750\n",
       "11        -0.604246           0.05          5          1000\n",
       "12        -0.584202           0.05          7           750\n",
       "13        -0.584201           0.05          7          1000\n",
       "14        -0.576201           0.05          9           750\n",
       "15        -0.576201           0.05          9          1000\n",
       "16        -0.597825           0.10          3           750\n",
       "17        -0.597824           0.10          3          1000\n",
       "18        -0.599179           0.10          5           750\n",
       "19        -0.599175           0.10          5          1000\n",
       "20        -0.613601           0.10          7           750\n",
       "21        -0.613601           0.10          7          1000\n",
       "22        -0.613664           0.10          9           750\n",
       "23        -0.613663           0.10          9          1000"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_frame = pd.DataFrame.from_dict( regressor.cv_results_)\n",
    "pd.concat([full_frame[['mean_test_score']], \n",
    "               json_normalize(regressor.cv_results_['params'])], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
