{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 Content-Based and Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Collaborative Filtering\n",
    "\n",
    "We'll use the Python \"surprise\" library.  This library offers several packages the support recommender systems, including nearest neighbor-based methods and matrix factoriaztion.  In this section, we'll take advantage of the nearest neighbor algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import gensim\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore, KNNBaseline, KNNBasic\n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "For our data, we'll use a \"The Movies Dataset\" from kaggle.  This dataset includes a table of 26 million ratings from hundreds of thousands of users.  We subset this data offline because finding a free method of storing this amount of data would be difficult.  Our subset includes all ratings from the top 10,000 users and top 2,000 movies.  The rating scale ranges between .5 and 5 in intervals of .5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18276.0</td>\n",
       "      <td>4545.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18276.0</td>\n",
       "      <td>4545.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18276.0</td>\n",
       "      <td>4205.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>8644.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "0  18276.0   4545.0     2.0\n",
       "1  18276.0   4545.0     2.0\n",
       "2  18276.0   4205.0     5.0\n",
       "3   9279.0   8644.0     2.5\n",
       "4   9279.0   8464.0     4.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'https://raw.githubusercontent.com/TheFedExpress/DATA612/master/Project2/movies_medium.csv'\n",
    "movies = (pd.read_csv(path)\n",
    "          .drop(['Unnamed: 0', 'timestamp'], axis = 1)\n",
    "          .dropna()\n",
    "#          .groupby(['userId', 'movieId'])\n",
    "#          .mean()\n",
    "#          .reset_index()\n",
    ")\n",
    "\n",
    "reader = Reader(rating_scale=(.5, 5))\n",
    "\n",
    "rec_data = Dataset.load_from_df(movies, reader)\n",
    "trainset = rec_data.build_full_trainset()\n",
    "\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/82.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_user = movies.groupby('userId')['rating'].mean()\n",
    "layout = {'xaxis' : {'title': 'avg rating'}, 'title' : 'Distribution of Average User Ratings',\n",
    "         'yaxis': {'title' : 'Users'}\n",
    "}\n",
    "data = [go.Histogram(x = avg_user.values)]\n",
    "py.iplot(go.Figure(data = data, layout = layout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most users are somewhat generous with their ratings, with a mode of 4.  Some users are tougher than others, indicating that we might want to standardize ratings by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/84.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_movie = movies.groupby('movieId')['rating'].mean()\n",
    "layout = {'xaxis' : {'title': 'avg rating'}, 'title' : 'Distribution of Average Movie Ratings',\n",
    "         'yaxis': {'title' : 'Movies'}\n",
    "}\n",
    "data = [go.Histogram(x = avg_movie.values)]\n",
    "py.iplot(go.Figure(data = data, layout = layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie ratings are a little less right-skewed.  There is a fair amount of weight between 1 and 3, indicating there are some unpopular movies in our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models\n",
    "\n",
    "\n",
    "The Surprise library frames recomendations a bit more like a regression problem than the recommenderlab package.  This is the reason for its sklearn-like api.  The dataset is the input and predicted ratings are the featured output attribute.  **This framework can still be used for recommendations by choosing items with the highest predicted rating.**\n",
    "\n",
    "We'll try 4 model types, 3 of which use a similarity matrix and take the K most similar users/items, however the expected rating is computed with slightly different formulas.  The last model type will be the baseline model.\n",
    "\n",
    "- KNNBasic: Raw ratings are weighted by similarities.  Item-based uses the given user's rating of the similar items, while user-based computes the expected rating of an item based on the similar user's rating of that item\n",
    "- KNNWithZScore: Similar to basic, but starts with the mean of a user/item and adds Z-scores weighted by similarity\n",
    "- KNNBaseline: Starts with the base line rating and adds (baseline rating - actual rating) of similar items/users weighte by similarity\n",
    "\n",
    "In testing the KNN models, we'll search over several hyperparameters to compare similarity measures, K, and user-based vs item-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'k' : [30,40,50], \n",
    "              'sim_options' : {'user_based': [False, True], \n",
    "              'name': ['cosine', 'pearson', 'pearson_baseline']}\n",
    "              \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mod(algo, data):\n",
    "\n",
    "    cv = GridSearchCV(algo, param_grid, cv = 3, n_jobs = -1)# set cv folds to 3 in the interst of time\n",
    "    cv.fit(data)\n",
    "\n",
    "    full_frame = pd.DataFrame.from_dict( cv.cv_results)\n",
    "    results_df = pd.concat([full_frame[['mean_test_rmse', 'mean_test_mae', 'param_k']], \n",
    "               json_normalize(cv.cv_results['param_sim_options'])], axis = 1)\n",
    "    return cv, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_mod(results_df, algo):\n",
    "\n",
    "    fig = tools.make_subplots(rows=1, cols=2, subplot_titles = ('Item Based', 'User Based'))\n",
    "    i = 1\n",
    "    for filter_type in  results_df.user_based.unique():\n",
    "        for item in results_df.name.unique():\n",
    "            df_temp = results_df.loc[(results_df.user_based == filter_type) & (results_df.name == item)]\n",
    "            trace = go.Scatter(\n",
    "                x = df_temp.param_k,\n",
    "                y = df_temp.mean_test_rmse,\n",
    "                mode = 'lines+markers',\n",
    "                name = item,\n",
    "            )\n",
    "            fig.append_trace(trace,1,i)\n",
    "            fig['layout']['yaxis1'].update(title = 'RMSE')\n",
    "            fig['layout']['xaxis' + str(i)].update(title = 'K')\n",
    "        i+=1\n",
    "    fig['layout'].update(title=algo)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750541</td>\n",
       "      <td>0.569211</td>\n",
       "      <td>0.082748</td>\n",
       "      <td>0.051861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768152</td>\n",
       "      <td>0.583043</td>\n",
       "      <td>0.094717</td>\n",
       "      <td>0.053887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.754012</td>\n",
       "      <td>0.568839</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.050894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.744977</td>\n",
       "      <td>0.566414</td>\n",
       "      <td>0.093749</td>\n",
       "      <td>0.050864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.754777</td>\n",
       "      <td>0.575358</td>\n",
       "      <td>0.107711</td>\n",
       "      <td>0.100731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_rmse  test_mae  fit_time  test_time\n",
       "0   0.750541  0.569211  0.082748   0.051861\n",
       "1   0.768152  0.583043  0.094717   0.053887\n",
       "2   0.754012  0.568839  0.110700   0.050894\n",
       "3   0.744977  0.566414  0.093749   0.050864\n",
       "4   0.754777  0.575358  0.107711   0.100731"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "algo = BaselineOnly()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cv1 = cross_validate(algo, rec_data, measures=['RMSE', 'MAE'], cv=5)\n",
    "pd.DataFrame.from_dict( cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/86.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cv, basic_results = cv_mod(KNNBasic, rec_data)\n",
    "basic_fig = graph_mod(basic_results, 'KNN Basic')\n",
    "py.iplot(basic_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/88.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore_cv, zscore_results = cv_mod(KNNWithZScore, rec_data)\n",
    "z_fig = graph_mod(zscore_results, 'KNN With Z-Score')\n",
    "py.iplot(z_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pgoodridge/90.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv, baseline_results = cv_mod(KNNBaseline, rec_data)\n",
    "base_fig = graph_mod(baseline_results, 'KNN KNNBaseline')\n",
    "py.iplot(base_fig, layout = layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- All 3 KNN-based models outperform the baseline model by a healthy margin\n",
    "- All 3 KNN-based models agree on the optimal hyperparameters, K equal to 30, item-based, and pearson_baseline as the similarity measure.\n",
    "\n",
    "The best performing model uses baseline ratings to as both the simiarity measure for the simiarity matrix and computing the expected rating.  This makes sense, as this both encodes more information into the simarity matrix and creates a more complex estimation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend Movies\n",
    "\n",
    "With the optimal hyperparameters and model-type in hand, we'll build a model using the full training set and show how this model can be used to power a recommendation engine.\n",
    "\n",
    "We create the \"anti_testset\", which includes all the item-user combinations not present in the training set.  This can be fed to the model object for predictions.  The predictions the be subsetted for a certain user and ranked for output.  Below, the top 10 recommendations for a given user are shown.\n",
    "\n",
    "*Note: Due to the metadata table being incomplete, we don't show actual movie names, though it would have been satisfying to do so.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>5525.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>7616.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>3457.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>7208.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>26547.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>4122.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>5515.0</td>\n",
       "      <td>4.952397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>9279.0</td>\n",
       "      <td>27741.0</td>\n",
       "      <td>4.920518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  Predicted Rating\n",
       "958   9279.0   3347.0          5.000000\n",
       "1039  9279.0   5525.0          5.000000\n",
       "1208  9279.0   7616.0          5.000000\n",
       "1140  9279.0   4789.0          5.000000\n",
       "720   9279.0   3457.0          5.000000\n",
       "1240  9279.0   7208.0          5.000000\n",
       "1061  9279.0  26547.0          5.000000\n",
       "887   9279.0   4122.0          5.000000\n",
       "1138  9279.0   5515.0          4.952397\n",
       "928   9279.0  27741.0          4.920518"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = KNNBaseline(k = 30, sim_options = {'name': 'pearson_baseline', 'user_based': False})\n",
    "best_knn.fit(trainset)\n",
    "\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = (pd.DataFrame(best_knn.test(testset), columns = ['userId', 'movieId', 'act_rating', 'Predicted Rating', 'details'])\n",
    "    .drop(columns = ['act_rating', 'details'])\n",
    ")\n",
    "predictions.loc[predictions.userId == 9279].sort_values('Predicted Rating', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Filtering\n",
    "\n",
    "With unstructured data, content-based filterting can be more difficult than collaborative filtering.  We will only show a simple model architecture for leveraging content-based filtering using LDA.  A more complex hybrid architecture could improve upon the above collaborative filtering approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and initialize libraries\n",
    "\n",
    "We will be creating a topic model using the overview field from the movie metadata.  Even though the ratings dataset does not include all 42,000 movies from the metadata table, the full dataset will create a better topic model.  Gensim will be our library of choice, though we will also use nltk for stemming and lemmatizing.\n",
    "\n",
    "Part of the art of topic modeling is choosing an appropriate stopword list.  For optimal results, this list sometimes needs to be hand-curated.  We leave the gender-specific pronouns in the list because they encode some meaning in the movie descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>budget</th>\n",
       "      <th>overview</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>30000000</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>65000000</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>0</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>16000000</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>0</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    budget                                           overview  runtime\n",
       "0    862  30000000  Led by Woody, Andy's toys live happily in his ...     81.0\n",
       "1   8844  65000000  When siblings Judy and Peter discover an encha...    104.0\n",
       "2  15602         0  A family wedding reignites the ancient feud be...    101.0\n",
       "3  31357  16000000  Cheated on, mistreated and stepped on, the wom...    127.0\n",
       "4  11862         0  Just when George Banks has recovered from his ...    106.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import re\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "import numpy as np\n",
    "\n",
    "path = 'https://raw.githubusercontent.com/TheFedExpress/DATA612/master/Project2/movies_metadata.csv'\n",
    "def make_int(df, column):\n",
    "    df = df.copy()\n",
    "    df[column] =  df[column].map(lambda x: x.replace('-', ''))\n",
    "    return df\n",
    "\n",
    "movies_metadata = (pd.read_csv(path)\n",
    "                       .loc[:, ['id', 'budget', 'overview', 'runtime']]\n",
    "                       .pipe(make_int, 'id')\n",
    "                       .drop_duplicates('id')\n",
    ")\n",
    "\n",
    "movies_metadata['id'] = movies_metadata['id'].astype(np.int32)\n",
    "movies_metadata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(desc):\n",
    "    words = []\n",
    "    try:\n",
    "        for item in simple_preprocess(desc, min_len = 3):\n",
    "             if item not in STOPWORDS or item in ['he', 'she', 'her', 'his']:\n",
    "                words.append(lemmatize_stemming(item))\n",
    "        return words\n",
    "    except(TypeError):\n",
    "        return np.nan\n",
    "\n",
    "movies_metadata['movie_words'] = movies_metadata['overview'].map(preprocess)\n",
    "movie_words = movies_metadata[['id', 'movie_words']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LDA Model\n",
    "\n",
    "We will build our model with 50 topics.  This number must be chosen apriori and usually takes some trial and error to get right.\n",
    "The most iteresting function parameters here are \"no_above\", \"no_below\".  \"no_above\" filters words from our corpus that only appear 2 or less times.  This smooths over some of the noise.  \"no_above\" removes words that appear in more than 50% of the documents.  This essentially identifies words that don't provide much information in our corpus, but are not in the stopword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(movie_words['movie_words'])\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=20000)\n",
    "dictionary.compactify()\n",
    "corpus = [dictionary.doc2bow(item) for item in movie_words['movie_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus = corpus, num_topics = 50, id2word = dictionary, passes = 10, alpha = .0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine output\n",
    "\n",
    "We'll look at the top words from the top 10 topics.  Here, we are looking for coherence; are the words related?  What story are they telling.  The first topic, for instance, seems to relate to thrillers and spy movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28,\n",
       "  '0.036*\"mysteri\" + 0.035*\"his\" + 0.033*\"investig\" + 0.031*\"murder\" + 0.022*\"secret\" + 0.022*\"agent\" + 0.017*\"detect\" + 0.013*\"kill\" + 0.013*\"disappear\" + 0.012*\"suspect\"'),\n",
       " (35,\n",
       "  '0.053*\"killer\" + 0.028*\"serial\" + 0.022*\"isol\" + 0.019*\"lock\" + 0.018*\"intim\" + 0.016*\"safe\" + 0.015*\"stone\" + 0.014*\"wall\" + 0.013*\"devot\" + 0.012*\"billi\"'),\n",
       " (21,\n",
       "  '0.043*\"master\" + 0.029*\"gold\" + 0.022*\"engin\" + 0.020*\"shadow\" + 0.018*\"inspector\" + 0.018*\"weekend\" + 0.016*\"simon\" + 0.016*\"jesus\" + 0.016*\"upsid\" + 0.015*\"imprison\"'),\n",
       " (38,\n",
       "  '0.085*\"school\" + 0.067*\"new\" + 0.061*\"high\" + 0.046*\"student\" + 0.031*\"york\" + 0.030*\"girl\" + 0.030*\"teacher\" + 0.024*\"colleg\" + 0.020*\"citi\" + 0.015*\"friend\"'),\n",
       " (15,\n",
       "  '0.101*\"his\" + 0.019*\"get\" + 0.014*\"money\" + 0.012*\"want\" + 0.012*\"friend\" + 0.011*\"job\" + 0.011*\"man\" + 0.011*\"time\" + 0.011*\"work\" + 0.010*\"tri\"'),\n",
       " (49,\n",
       "  '0.060*\"murder\" + 0.054*\"polic\" + 0.037*\"crime\" + 0.032*\"offic\" + 0.018*\"case\" + 0.017*\"innoc\" + 0.016*\"kill\" + 0.015*\"accus\" + 0.014*\"trial\" + 0.013*\"simpl\"'),\n",
       " (29,\n",
       "  '0.032*\"univers\" + 0.024*\"imag\" + 0.019*\"examin\" + 0.018*\"air\" + 0.015*\"price\" + 0.014*\"icon\" + 0.014*\"observ\" + 0.013*\"health\" + 0.013*\"rule\" + 0.013*\"landscap\"'),\n",
       " (16,\n",
       "  '0.044*\"prison\" + 0.039*\"state\" + 0.028*\"unit\" + 0.026*\"escap\" + 0.019*\"camp\" + 0.018*\"indian\" + 0.018*\"nazi\" + 0.015*\"guard\" + 0.015*\"attack\" + 0.013*\"frank\"'),\n",
       " (34,\n",
       "  '0.116*\"film\" + 0.047*\"star\" + 0.045*\"movi\" + 0.036*\"play\" + 0.031*\"comedi\" + 0.024*\"direct\" + 0.023*\"director\" + 0.019*\"role\" + 0.017*\"actor\" + 0.016*\"classic\"'),\n",
       " (19,\n",
       "  '0.030*\"ring\" + 0.026*\"sam\" + 0.025*\"red\" + 0.024*\"belong\" + 0.022*\"alli\" + 0.020*\"itali\" + 0.020*\"nuclear\" + 0.018*\"cost\" + 0.016*\"insight\" + 0.016*\"cure\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = lda.print_topics(num_topics = 10)\n",
    "topics = [lda.get_document_topics(element) for element in corpus]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics appear to be fairly coherent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic Percentage to Each Movie\n",
    "\n",
    "This information is a by-product of the topic model.  Each document in the corpus is assigned topic percentages that add up to 100%.  In the LDA model, this represents the probability of a word belonging to a given topic given a particular document.  These are the main features we will be using for our content-based recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clus = []\n",
    "for i in range(len(topics)):\n",
    "    for j in range(len(topics[i])):\n",
    "        if topics[i][j][1] >= .1:\n",
    "            all_clus.append({\"id\": movie_words.iloc[i, 0], \"top_num\":topics[i][j][0], \"percentage\":topics[i][j][1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>budget</th>\n",
       "      <th>overview</th>\n",
       "      <th>runtime</th>\n",
       "      <th>movie_words</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>30000000</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[lead, woodi, andi, toy, live, happili, his, r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.116272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>65000000</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[sibl, judi, peter, discov, enchant, board, ga...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>0</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[famili, wed, reignit, ancient, feud, door, ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>16000000</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[cheat, mistreat, step, women, hold, breath, w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>0</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[georg, bank, recov, his, daughter, wed, recei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.279927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId    budget                                           overview  \\\n",
       "0      862  30000000  Led by Woody, Andy's toys live happily in his ...   \n",
       "1     8844  65000000  When siblings Judy and Peter discover an encha...   \n",
       "2    15602         0  A family wedding reignites the ancient feud be...   \n",
       "3    31357  16000000  Cheated on, mistreated and stepped on, the wom...   \n",
       "4    11862         0  Just when George Banks has recovered from his ...   \n",
       "\n",
       "   runtime                                        movie_words   0         1  \\\n",
       "0     81.0  [lead, woodi, andi, toy, live, happili, his, r... NaN       NaN   \n",
       "1    104.0  [sibl, judi, peter, discov, enchant, board, ga... NaN       NaN   \n",
       "2    101.0  [famili, wed, reignit, ancient, feud, door, ne... NaN       NaN   \n",
       "3    127.0  [cheat, mistreat, step, women, hold, breath, w... NaN  0.241188   \n",
       "4    106.0  [georg, bank, recov, his, daughter, wed, recei... NaN       NaN   \n",
       "\n",
       "    2   3   4 ...        40        41  42        43  44        45        46  \\\n",
       "0 NaN NaN NaN ...       NaN  0.116272 NaN       NaN NaN  0.135838       NaN   \n",
       "1 NaN NaN NaN ...       NaN       NaN NaN       NaN NaN       NaN       NaN   \n",
       "2 NaN NaN NaN ...  0.215810       NaN NaN       NaN NaN       NaN       NaN   \n",
       "3 NaN NaN NaN ...       NaN       NaN NaN       NaN NaN       NaN       NaN   \n",
       "4 NaN NaN NaN ...  0.149779       NaN NaN  0.135961 NaN       NaN  0.279927   \n",
       "\n",
       "   47  48  49  \n",
       "0 NaN NaN NaN  \n",
       "1 NaN NaN NaN  \n",
       "2 NaN NaN NaN  \n",
       "3 NaN NaN NaN  \n",
       "4 NaN NaN NaN  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = (pd.DataFrame(all_clus)\n",
    "              .pivot(index = 'id', columns = 'top_num', values = 'percentage')\n",
    ")\n",
    "full_df = movies_metadata.merge(new_df, on = 'id').rename(columns = {'id': 'movieId'})\n",
    "full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Recommendation Model\n",
    "\n",
    "In this simple example, we'll frame recommendation as a supervised machine learning problem.  The LDA topics, budget, and runtime will be our features and user ratings will be our target.  To further simplify things, we'll assume each user has a separate model based on their past rating history.  XGBoost will be used as our regressor.\n",
    "\n",
    "A slightly more complex architecture would be to use XGBoost as a feature transformer for the movie content and input that into a mixed model with the user as a random effect.  That would somewhat mitigate the cold-start issue.  That approach is discussed here:\n",
    "\n",
    "https://engineering.linkedin.com/blog/2019/04/ai-behind-linkedin-recruiter-search-and-recommendation-systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "533.0    2970\n",
       "741.0    2233\n",
       "483.0    2231\n",
       "543.0    1904\n",
       "557.0    1728\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.groupby('userId').size().sort_values(ascending = False).head(5)#Select user for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=-1, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.6),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'max_depth': [3, 5, 7, 9], 'n_estimators': [750, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "final_df = movies.merge(full_df, on = 'movieId')\n",
    "\n",
    "def impute_median(df, column):\n",
    "    df = df.copy()\n",
    "    df[column] = df.loc[df[column] == 0, column].median()\n",
    "    return df\n",
    "\n",
    "X = (final_df.pipe(impute_median, 'budget')\n",
    "         .pipe(impute_median, 'runtime')\n",
    "         .fillna(0)\n",
    "         .drop(columns = ['rating', 'userId', 'movieId', 'overview', 'movie_words'])\n",
    "         .loc[final_df['userId'] == 533]\n",
    ")\n",
    "y = final_df.loc[final_df['userId'] == 533, 'rating']\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'learning_rate': [.01, .05, .1],\n",
    "    'max_depth': [3,5,7,9],\n",
    "    'n_estimators': [750, 1000]\n",
    "    \n",
    "}\n",
    "gb = xgb.XGBRegressor(objective = 'reg:linear', subsample = .6, colsample_bytree = .6, nthread = -1)\n",
    "regressor = GridSearchCV(gb, xgb_param_grid, cv = 3, scoring = 'neg_mean_squared_error')\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.669251</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.681718</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.664323</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.667708</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.671259</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.673228</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.679478</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.681272</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.672301</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.672297</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.638080</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.638076</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.654655</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.654653</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.650961</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.650956</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.673415</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.673417</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.630960</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.630955</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.642061</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.642058</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.645083</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.645081</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  learning_rate  max_depth  n_estimators\n",
       "0         -0.669251           0.01          3           750\n",
       "1         -0.681718           0.01          3          1000\n",
       "2         -0.664323           0.01          5           750\n",
       "3         -0.667708           0.01          5          1000\n",
       "4         -0.671259           0.01          7           750\n",
       "5         -0.673228           0.01          7          1000\n",
       "6         -0.679478           0.01          9           750\n",
       "7         -0.681272           0.01          9          1000\n",
       "8         -0.672301           0.05          3           750\n",
       "9         -0.672297           0.05          3          1000\n",
       "10        -0.638080           0.05          5           750\n",
       "11        -0.638076           0.05          5          1000\n",
       "12        -0.654655           0.05          7           750\n",
       "13        -0.654653           0.05          7          1000\n",
       "14        -0.650961           0.05          9           750\n",
       "15        -0.650956           0.05          9          1000\n",
       "16        -0.673415           0.10          3           750\n",
       "17        -0.673417           0.10          3          1000\n",
       "18        -0.630960           0.10          5           750\n",
       "19        -0.630955           0.10          5          1000\n",
       "20        -0.642061           0.10          7           750\n",
       "21        -0.642058           0.10          7          1000\n",
       "22        -0.645083           0.10          9           750\n",
       "23        -0.645081           0.10          9          1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_frame = pd.DataFrame.from_dict( regressor.cv_results_)\n",
    "pd.concat([full_frame[['mean_test_score']], \n",
    "               json_normalize(regressor.cv_results_['params'])], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The collaborative filtering approach seemed viable, almost right out of the box.  The RMSE for predicted ratings was less than half a star and making recommendations is as easy as sorting predicted ratings.  Content-based would need a fair amount of additional work to beat that standard, but it does have its advantages.  The content-based seems more scalable as the userbase grows because similarity matricies do not need to be computed.  A hybrid of the two would likely lead to the best performance, as each provides unique information explaining the variance in user ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "    \n",
    "- data: https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    "- LDA preprocessing: https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "- Surprise documentation: https://surprise.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
