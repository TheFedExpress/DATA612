{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights from Music Recommendations at Scale\n",
    "\n",
    "### Supervised vs Unsupervised\n",
    "\n",
    "In the last discussion, I believe I refered to matrix factorization as an unsupervised machine learning problem.  In some contexts factoriaztion is unsupervised, such as PCA of your model matrix in regression.  The y labels are not used so the eigenvectors are computed with no knowledge of the target.  With the definition of the matrix factorization problem in the presentation, it became apparent that it is a supervised problem.  Rating is both the target variable and makes up the cells of the user-item matrix so in minimizing the ALS equation, you are building factors that minimize error in rating.  \n",
    "\n",
    "### Gridify\n",
    "\n",
    "As someone without experience in map-reduce techniques, the “full gridify” method was intriguing.  I’ve seen other performance tricks, such queries divided up into parts or tables sliced into partitions, but the structured approach to the matrix operations seemed ingenious.  I spend a while trying to understand the specifics of each step and why it’s being done so I’ve itemized “the what and why” for each step.  Hopefully this I picked up some points from the presentation that are helpful and I'd appreciate feedback to help me better understand the pieces I missed.\n",
    "\n",
    "1.       Split the ratings matrix into blocks and send each block to a different worker.\n",
    "\n",
    "2.       Compute YtY and broadcast to each worker. YtY is needed for the least squares formula, never changes, and the output is only n by n where n is the number of latent dimensions chosen.\n",
    "\n",
    "3.       Send an item vector to each worker that had a user that rated that item.  Compute intermediate terms.  What intermediate terms are computed here?\n",
    "\n",
    "4.       Shift vectors around and aggregate (exactly what is switched around?).  The full ratings vector for each user (or at least the items the user rated) are needed for both user averages and the least squares formula.  The user's ratings would be the target in the formula so this is why you'd need all non-null ratings.\n",
    "\n",
    "5. The same steps are repeated with users and items switched.  \n",
    "6. Repeat N times where N is the number of iterations chosen.\n",
    "\n",
    "I can see how performance is improved greatly if you can load all user/items ratings vectors in memory at once, I'd just like to know the specifics on the arithmetic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
